<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			* {
				box-sizing: border-box;
			}
			h1 {
				text-align: center;
			}

			.container {
				display: flex;
				flex-direction: column;
				align-items: center;
				justify-content: center;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
				border-radius: 5px;
			}

			body {
				font-family: 'Inter', sans-serif;
			    margin: auto;
				width: 80%; 
			}
			.column {
				float: left;
				width: 50%;
				padding: 5px;
			}
			.column2 {
				float: left;
				width: 33.33%;
				padding: 5px;
			}
			.column3 {
				float: left;
				width: 25%;
				padding: 5px;
			}
			.column4 {
				float: left;
				width: 100%;
				padding: 5px;
			}
			.row::after {
			content: "";
			clear: both;
			display: table;
			}

			table,
			th,
			td {
				border: 1px solid black;
				border-collapse: collapse;
			}
			th,
			td {
				padding: 20px;
			}
		</style>
	</head>
	<body>
		<div class="container">
			<h1>Project 3: (Auto)stitching and Photo Mosaics</h1>
			<div style="text-align: center;">Name: Alexander Waldman </div>
			<div style="text-align: center;"><a href = "../">← Back to Homepage</a></div>
			
			<h1>Part A: Image Warping and Mosaicing</h1>

			<h2>A.1: Shoot the Pictures</h2>
			<p>Before I could begin creating mosaics by registering, projective warping, resampling, and compositing image data, I needed to capture photos that were well suited for this project. Inspired by Cal's detailed architecture and lush nature, I took pictures of some of my favorite places on campus, making sure to keep the center of projection fixed while I rotated my camera. </p>
			<div class="row">
				<div class="column2" style="text-align: center;">
					<img src="./images/mining1.jpg" alt="mining1" style="width:100%">
					<figcaption></figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/mining2.jpg" alt="mining2" style="width:100%">
					<figcaption>Hearst Mining Circle</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/mining3.jpg" alt="mining3" style="width:100%">
					<figcaption></figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column2" style="text-align: center;">
					<img src="./images/haviland1.jpg" alt="campanile1" style="width:100%">
					<figcaption></figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/haviland2.jpg" alt="campanile2" style="width:100%">
					<figcaption>Haviland Hall</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/haviland3.jpg" alt="campanile3" style="width:100%">
					<figcaption></figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column2" style="text-align: center;">
					<img src="./images/eucalyptus1.jpg" alt="eucalyptus1" style="width:100%">
					<figcaption></figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/eucalyptus2.jpg" alt="eucalyptus2" style="width:100%">
					<figcaption>The Eucalyptus Grove</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/eucalyptus3.jpg" alt="eucalyptus3" style="width:100%">
					<figcaption></figcaption>
				</div>
			</div>
			<h2>A.2: Recover Homographies</h2>
			<p><b>To generate all relevant images for this section, run the following command: <code>python main.py a_2</code></b></p>
			<p>In order to warp my images into alignment, I first needed to solve for the transformation matrix that allows us to map one perspective projection to another. This 3x3 matrix is called the homography. To solve for this matrix, you can set up a system of equations to map points from one image to another, using least squares estimation to derive the homography:</p>
			<ol>
				<li>Identify points <code>(x, y)</code> in the first image that correspond with points <code>(u, v)</code> in the second image. In the second part of the project, this part will be done automatically. For now, I used this <a href="https://cal-cs180.github.io/fa23/hw/proj3/tool.html">tool</a> to identify correspondences.</li>
				<li>For each pair of points <code>(x<sub>i</sub>, y<sub>i</sub>)</code> and <code>(u<sub>i</sub>, v<sub>i</sub>)</code>, we have this relation where h<sub>1</sub>, ..., h<sub>8</sub> are entries in the homography matrix.</li>
				<img src="./images/corr.png" style="width: 400px">
				<li>From here, we can use algebra to arrive at the equations h<sub>1</sub>x+h<sub>2</sub>y+h<sub>3</sub>−uh<sub>7</sub>x−uh<sub>8</sub>y=u and h<sub>4</sub>x+h<sub>5</sub>y+h<sub>6</sub>−vh<sub>7</sub>x−vh<sub>8</sub>y=v. In matrix form, this looks like</li>
				<img src="./images/qwert.png" style="width: 400px">
				<li>For each additional correspondence, you can extend the matrices like this.</li>
				<img src="./images/fullmat.png" style="width: 400px">
			</ol>
			<p>Since the homography matrix has 8 unknowns (the 9th value is always 1), we need at least 8 equations to reach a unique solution. This means that we need at least 4 correspondences to map one image onto another. In practice, using just 4 points can be very unstable, as being off by a few pixels can lead to large errors. For the images below (and the rest of the mosaic images), I used about 20 correspondences.</p>
			<div class="row">
				<div class="column" style="text-align: center;">
					<img src="./images/wheeler1_dots.png" alt="wheeler1 dots" style="width:100%">
					<figcaption>Points in left image</figcaption>
				</div>
				<div class="column" style="text-align: center;">
					<img src="./images/wheeler2_dots1.png" alt="wheeler2 dots" style="width:100%">
					<figcaption>Corresponding points in center image</figcaption>
				</div>
			</div>
			<img src="./images/wheeler12_homog.png" style="width: 500px;">
			<figcaption>Recovered homography</figcaption>
			<div class="row">
				<div class="column" style="text-align: center;">
					<img src="./images/wheeler3_dots.png" alt="wheeler3 dots" style="width:100%">
					<figcaption>Points in right image</figcaption>
				</div>
				<div class="column" style="text-align: center;">
					<img src="./images/wheeler2_dots3.png" alt="wheeler2 dots" style="width:100%">
					<figcaption>Corresponding points in center image</figcaption>
				</div>
			</div>
			<img src="./images/wheeler32_homog.png" style="width: 500px;">
			<figcaption>Recovered homography</figcaption>

			<h2>A.3: Warp the Images</h2>
			<p><b>To generate all relevant images for this section, run the following command: <code>python main.py a_3</code></b></p>
			<p>Now that we have the ability to recover homographies we can begin warping images onto one another. One common use case for homographies is image rectification, often used when taking pictures of important documents. I decided to demonstrate my ability to rectify images using a couple poster that I have hanging in my apartment. Using the pixel correspondence tool I mentioned earlier, I mapped the corners of each poster to the corners of the image so that the homography would result in a totally flat picture of the poster. Having a correct homography is only one part of the process, though. Since pixels in the input image are unlikely to align perfectly with pixels in the output image, we need some kind of interpolation technique to ensure the result doesn't have holes. I implemented two types of interpolation, nearest neighbor and bilinear. Given a pixel location in the output image, nearest neighbor assigns its value to the closest corresponding pixel from the input image while bilinear interpolation involves finding a weighted average of the four closest pixels in the input. Despite its relative slowness, I preferred using bilinear interpolation when producing images for this assignment.</p> 
			<div class="row">
				<div class="column2" style="text-align: center;">
					<img src="./images/poster2.jpg" alt="poster2" style="width:100%;height: 100%">
					<figcaption>Original</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/rectified2_nearest.png" alt="poster2_nn" style="width:100%;">
					<figcaption>Rectified with nearest neighbor interpolation</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/rectified2_bilinear.png" alt="poster2_bil" style="width:100%">
					<figcaption>Rectified with bilinear interpolation</figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column2" style="text-align: center;">
					<img src="./images/poster1.jpg" alt="poster1" style="width:100%">
					<figcaption>Original</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/rectified1_nearest.png" alt="poster1_nn" style="width:100%">
					<figcaption>Rectified with nearest neighbor interpolation</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/rectified1_bilinear.png" alt="poster1_bil" style="width:100%">
					<figcaption>Rectified with bilinear interpolation</figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column" style="text-align: center;">
					<img src="./images/ball_nn.png" alt="nearest neighbor" style="width:100%">
					<figcaption>Nearest neighbor interpolation result</figcaption>
				</div>
				<div class="column" style="text-align: center;">
					<img src="./images/ball_bi.png" alt="bilinear" style="width:100%">
					<figcaption>Bilinear interpolation result</figcaption>
				</div>
			</div>
			<p>Rectification works! We can also see the difference between using nearest neighbor and bilinear interpolation on an image. Up close, images that used nearest neighbor definetly look more pixelated than those with bilinear interpolation. The averaging of values in bilinear interpolation allows for a much smoother output, but this comes at the cost of time. Bilinear interpolation involves many more mathethatical operations compared to the nearest neighbor approach, which simply rounds values to the nearest integer. </p>
			<h2>A.4: Blend the Images into a Mosaic</h2>
			<p><b>To generate all relevant images for this section, run the following command: <code>python main.py a_4</code></b></p>
			<p>Finally, we can begin producing image mosaics! My process for creating image mosaics works as follows:</p>
			<ol>
				<li>Using manually selcted correspondences, compute the homography between the left image and the center image as well as the homography between the right image and the center image.</li>
				<li>Warp both the left image and the right image onto the center image.</li>
				<li>Pipe the four corners of the left image and the right image through their respective H transforms to determine the dimensions of the final mosaic.</li>
				<li>Place the center image and each warped image on their own canvas with the dimensions determined in step 3 where the top left corner of the bounding box maps to (0,0). Additionally, add an alpha channel to each image</li>
				<li>Feather the center image, decreasing its alpha values in relation to the pixel's distance from the center point of the image on the canvas (not necessarily the center of the canvas, as the image may not find itself in the exact middle of the canvas after step 3)</li>
				<li>Create two mosaics, one with the warped left image and the feathered center image (Mosaic 1), and the other with the right image and the feathered center image (Mosaic 2).</li>
				<li>To create the final mosaic. Combine the left half of Mosaic 1 with the right half of Mosaic 2.</li>
			</ol>
			<div class="row">
				<div class="column2" style="text-align: center;">
					<img src="./images/eucalyptus1.jpg" alt="eucalyptus1" style="width:100%">
					<figcaption></figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/eucalyptus2.jpg" alt="eucalyptus2" style="width:100%">
					<figcaption>Original images</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/eucalyptus3.jpg" alt="eucalyptus3" style="width:100%">
					<figcaption></figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column4" style="text-align: center;">
					<img src="./images/eucalyptus_mosaic.png" alt="eucalyptus_mosaic" style="width:100%">
					<figcaption>Stitched mosaic</figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column2" style="text-align: center;">
					<img src="./images/bench1.jpg" alt="bench1" style="width:100%">
					<figcaption></figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/bench2.jpg" alt="bench2" style="width:100%">
					<figcaption>Original images</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/bench3.jpg" alt="bench3" style="width:100%">
					<figcaption></figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column4" style="text-align: center;">
					<img src="./images/bench_mosaic.png" alt="bench_mosaic" style="width:100%">
					<figcaption>Stitched mosaic</figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column2" style="text-align: center;">
					<img src="./images/wheeler1.jpg" alt="wheeler1" style="width:100%">
					<figcaption></figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/wheeler2.jpg" alt="wheeler2" style="width:100%">
					<figcaption>Original images</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/wheeler3.jpg" alt="wheeler3" style="width:100%">
					<figcaption></figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column4" style="text-align: center;">
					<img src="./images/wheeler_mosaic.png" alt="wheeler_mosaic" style="width:100%">
					<figcaption>Stitched mosaic</figcaption>
				</div>
			</div>

			<p>As you can see, things worked out pretty well. The results are not perfect, however. There is a fair amount of ghosting/blurriness in some of the high frequency areas of the image. This is especially visible in the leaves of the Eucalyptus trees in the second mosaic. I believe the main cause of this issue is my choice of correspondence points. When choosing correspondence points, the high amount of detail in some parts of the images made it really hard to find a pixel-perfect correspondence for a given point. I ended up focusing most of the points around prominent elements with clear edges/corners. As a result, the homography is only able to warp those parts of the image super accurately. As we move to auto-stitching later on, this will hopefully not be an issue.</p>
			
			<h2>B.1: Harris Corner Detection</h2>
			<p><b>To generate all relevant images for this section, run the following command: <code>python main.py b_1</code></b></p>
			<p>The first step of stitching images automatically involves detecting prominent features or "corners" that we can use to find correspondences between images later on. I found these corners using a Harris detector, which essentially locates all points in an image where there is significant change in the x and y direction. Luckily, we were provided some sample code for single-scale harris detection, which I used to generate the image below:</p>
			<div class="row">
				<div class="column" style="text-align: center;">
					<img src="./images/haviland2.jpg" alt="haviland" style="width:100%">
					<figcaption>Original Photo</figcaption>
				</div>
				<div class="column" style="text-align: center;">
					<img src="./images/harris_detection.jpg" alt="harris pts" style="width:100%">
					<figcaption>Detected corners</figcaption>
				</div>
			</div>
			<p>As you can see, using Harris detection results in very large number of corners (1186 in this case). For the purposes of alignment, having this many corners/interest points is not necessary and will affect runtime significantly. One easy way to restrict the number of points I'm considering is to filter for the N strongest points in the image, where strength refers to the value of the corner response function R (calculated during the Harris detection process) at a particular point.</p>
			<div class="row">
				<div class="column" style="text-align: center;">
					<img src="./images/top_250_corners.jpg" alt="top 250" style="width:100%">
					<figcaption>Strongest 250 corners</figcaption>
				</div>
				<div class="column" style="text-align: center;">
					<img src="./images/top_500_corners.jpg" alt="top 500" style="width:100%">
					<figcaption>Strongest 500 corners</figcaption>
				</div>
			</div>
			<p>Unfortunately, filtering for the N strongest corners leaves us with a very uneven spatial distribution of interest points. If we continued from here without making the distribution more even, the least squares estimation used to calculate the homography would not include many points from sparsely populated areas like the stairs in the images above. The homography would not perform well when it comes to warping that part of the image, leading to significant ghosting/blurring. To avoid that, I implemented Adaptive Non-Maximal Suppression (ANMS) to find corners that are strong <b>and</b> distributed evenly throughout the image. My implementation works as follows:</p>
			<ol>
				<li>For each Harris corner <code>c_i</code>:
					<ul>
						<li>Find all other Harris corners <code>c_j</code> in the image such that <code>strength(c_i) < 0.9 * strength(c_j)</code></li>
						<li>Calculate the distance from <code>c</code> to all other strong Harris corners and find the minimum</li>
						<li>If there are no corners such that <code>strength(c_i) < 0.9 * strength(c_j)</code>, set <code>c_i</code>'s minimum distance to infinity</li>
					</ul>
				</li>
				<li>Sort the Harris corners by their minimum distance to another strong corner in descending order</li>
			</ol>
			<p>Now, if we take the top 250 or top 500 Harris corners sorted by their minimum distance to another strong corner, we get evenly distributed interest points!</p>
			<div class="row">
				<div class="column" style="text-align: center;">
					<img src="./images/anms_250.jpg" alt="anms 250" style="width:100%">
					<figcaption>ANMS 250</figcaption>
				</div>
				<div class="column" style="text-align: center;">
					<img src="./images/anms_500.jpg" alt="hanms 500" style="width:100%">
					<figcaption>ANMS 500</figcaption>
				</div>
			</div>
			<h2>B.2: Feature Descriptor Extraction</h2>		
			<p><b>To generate all relevant images for this section, run the following command: <code>python main.py b_2</code></b></p>
			<p>Now that we can find prominent, evenly distributed points in an image, we need to find a way to match those points to locations in another image. There's no way to guarantee that the Harris corners in one image match the Harris corners in another image, so we need to get creative. In order to match Harris corners across images, we need to create feature descriptors. A feature descriptor is an bias/gain normalized 8X8 pixel patch centered around an interest point that samples surrounding pixels at a low frequency. Normalizing helps us combat changes in light intensity bewteen images, while sampling at a lower frequency makes the descriptors a bit less sensitive to their exact location (which makes matching easier later on). My implementation of feature descriptors works as follows:</p>	
			<ol>
				<li>Read in the image as black and white and apply a Gaussian blur (I used a kernel size of 13 and &#963; = 2).</li>
				<li>Find a set of evenly distributed Harris corners using ANMS.</li>
				<li>For each corner <code>c</code>
					<ul>
						<li>Set <code>x</code> and <code>y</code> equal to the rounded x and y coordinates of <code>c</code>.</li>
						<li>Find the 40x40 pixel window in the blurred balck and white image centered at <code>(x, y)</code>.</li>
						<li>Sample the 40x40 window with a spacing of 5 pixels between each sample (resulting in a size of 8x8) and set that equal to <code>patch</code>.</li>
						<li>Normalize <code>patch</code> by subtracting the mean and dividing by the standard deviation.</li>
						<li>Flatten <code>patch</code> into a 1D vector and store for later use.</li>
					</ul>
				</li>
			</ol>
			<p>Using the image of Haviland Hall from part B.1, I applied these steps to create feature descriptors for the top 500 ANMS corners. Pictured below are a few examples of what the feature descriptors look like.</p>
			<div class="row">
				<div class="column2" style="text-align: center;">
					<img src="./images/feature_descriptor_445_186.jpg" alt="descriptor (445, 186)" style="width:100%">
					<figcaption>Feature descriptor for corner at (445, 186)</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/feature_descriptor_466_185.jpg" alt="descriptor (466, 185)" style="width:100%">
					<figcaption>Feature descriptor for corner at (466, 185)</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/feature_descriptor_46_615.jpg" alt="descriptor (46, 615)" style="width:100%">
					<figcaption>Feature descriptor for corner at (46, 615)</figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column2" style="text-align: center;">
					<img src="./images/feature_descriptor_612_212.jpg" alt="descriptor (612, 212)" style="width:100%">
					<figcaption>Feature descriptor for corner at (612, 212)</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/feature_descriptor_72_553.jpg" alt="descriptor (72, 553)" style="width:100%">
					<figcaption>Feature descriptor for corner at (72, 553)</figcaption>
				</div>
				<div class="column2" style="text-align: center;">
					<img src="./images/feature_descriptor_962_126.jpg" alt="descriptor (962, 126)" style="width:100%">
					<figcaption>Feature descriptor for corner at (962, 126)</figcaption>
				</div>
			</div>
			<h2>B.3: Feature Matching</h2>
			<p><b>To generate all relevant images for this section, run the following command: <code>python main.py b_3</code></b></p>
			<p>From here, we can begin finding matching feature descriptors bewteen images and identifying correspondences! The naive approach to finding matches between two images works like this. For every feature descriptor in image 1, loop through every feature descriptor in image 2. Calculate their L2 distance and match the feature descriptor from image 1 with the feature descriptor from image 2 that minimizes L2 distance. While you may end up finding some good matches, you'll also end up matching a lot of outliers with feature descriptors that don't really match but just happen to minimize L2 distance. A clever way to get around this is to use Lowe's trick. When finding the smallest L2 distance between two descriptors, you can also find the second-smallest L2 distance. Then, the ratio of the smallest L2 distance to the second smallest L2 distance will tell you how good the match is. When the ratio is small, that means you've found a good match since the pairing with the smallest distance is much better than the pairing with the second smallest distance. By only keeping the matches whose ratio is below a certain threshold <code>t</code>, you can eliminate almost all outliers! In my experience, I found <code>t=0.7</code> returned lots of good matches while getting rid of most of the outliers. Below, I've visualized the matched features for images of Haviland Hall and plotted the correspondences. You'll notice there are still a few mismatched features present, but those will not have an effect on the final image thanks to the RANSAC algorithm implemented in B.4</p>
			<div class="row">
				<div class="column3" style="text-align: center;">
					<img src="./images/b3_anms_left.jpg" alt="anms left" style="width:100%">
					<figcaption>ANMS 500</figcaption>
				</div>
				<div class="column3" style="text-align: center;">
					<img src="./images/b3_anms_center.jpg" alt="anms center" style="width:100%">
					<figcaption>ANMS 500</figcaption>
				</div>
				<div class="column3" style="text-align: center;">
					<img src="./images/b3_matching_left_center.jpg" alt="matching pts left" style="width:100%">
					<figcaption>Matched features, t = 0.7</figcaption>
				</div>
				<div class="column3" style="text-align: center;">
					<img src="./images/b3_matching_center_left.jpg" alt="macthing pts center" style="width:100%">
					<figcaption>Matched features, t = 0.7</figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column4" style="text-align: center;">
					<img src="./images/b3_corresponding_left_center.jpg" alt="Corresponding points" style="width:100%">
					<figcaption>Corresponding points</figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column3" style="text-align: center;">
					<img src="./images/b3_anms_right.jpg" alt="anms center" style="width:100%">
					<figcaption>ANMS 500</figcaption>
				</div>
				<div class="column3" style="text-align: center;">
					<img src="./images/b3_anms_center.jpg" alt="anms right" style="width:100%">
					<figcaption>ANMS 500</figcaption>
				</div>
				<div class="column3" style="text-align: center;">
					<img src="./images/b3_matching_right_center.jpg" alt="matching pts center" style="width:100%">
					<figcaption>Matched features, t = 0.7</figcaption>
				</div>
				<div class="column3" style="text-align: center;">
					<img src="./images/b3_matching_center_right.jpg" alt="matching pts right" style="width:100%">
					<figcaption>Matched features, t = 0.7</figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column4" style="text-align: center;">
					<img src="./images/b3_corresponding_right_center.jpg" alt="Corresponding points" style="width:100%">
					<figcaption>Corresponding points</figcaption>
				</div>
			</div>
			<h2>B.4: RANSAC for Robust Homography</h2>
			<p><b>To generate all relevant images for this section, run the following command: <code>python main.py b_4</code></b></p>
			<p>Now that we have our correspondences, all that's left is to solve for a homography that can map these matched features onto each other. As I mentioned at the end of the last section, however, we still have some outliers/mismatches to deal with. In order to whittle down my list of correspondences to a list of "good" correspondences, I implemented the RANSAC algorithm introduced in lecture.</p>
			<img src="./images/ransac_loop.png" style="width:500px">
			<p>For my autostitched images, I chose to use a &#949; value of 1.0 to ensure the set of inliers I found during an iteration of RANSAC were very accurate to ensure the final homography could warp things properly. With everything implemented, we can revisit the mosaic from part A, but this time we can use autostitching!</p>
			<div class="row">
				<div class="column4" style="text-align: center;">
					<img src="./images/eucalyptus_mosaic.png" alt="eucalyptus_mosaic" style="width:100%">
					<figcaption>Manually stitched images of the Eucalyptus grove</figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column4" style="text-align: center;">
					<img src="./images/eucalyptus_autostitch.png" alt="eucalyptus_autostitch" style="width:100%">
					<figcaption>Autostitched images of the Eucalyptus grove</figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column4" style="text-align: center;">
					<img src="./images/bench_mosaic.png" alt="bench_mosaic" style="width:100%">
					<figcaption>Manually stitched images of a bench</figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column4" style="text-align: center;">
					<img src="./images/bench_autostitch.png" alt="haviland_autostitch" style="width:100%">
					<figcaption>Autostitched images of a bench</figcaption>
				</div>
			</div>
			<div class="row">
				<div class="column4" style="text-align: center;">
					<img src="./images/wheeler_mosaic.png" alt="wheeler_mosaic" style="width:100%">
					<figcaption>Manually stitched images of Wheeler Hall</figcaption>
				</div>
			</div>			
			<div class="row">
				<div class="column4" style="text-align: center;">
					<img src="./images/wheeler_autostitch.png" alt="wheeler_autostitch" style="width:100%">
					<figcaption>Autostitched images of Haviland Hall</figcaption>
				</div>
			</div>
		</div>
	</body>
</html>
